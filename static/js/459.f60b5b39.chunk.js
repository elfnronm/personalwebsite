"use strict";(self.webpackChunkportfolio_website=self.webpackChunkportfolio_website||[]).push([[459],{459:(e,t,s)=>{s.r(t),s.d(t,{default:()=>C});var i=s(43),a=s(487),l=s(579),n=s(190),r=s(930),o=s(293),c=s(555),d=s(674),x=s(676),h=s(51);class m extends i.Component{getSnapshotBeforeUpdate(e){const t=this.props.childRef.current;if(t&&e.isPresent&&!this.props.isPresent){const e=t.offsetParent,s=(0,x.s)(e)&&e.offsetWidth||0,i=this.props.sizeRef.current;i.height=t.offsetHeight||0,i.width=t.offsetWidth||0,i.top=t.offsetTop,i.left=t.offsetLeft,i.right=s-i.width-i.left}return null}componentDidUpdate(){}render(){return this.props.children}}function p(e){let{children:t,isPresent:s,anchorX:a}=e;const n=(0,i.useId)(),r=(0,i.useRef)(null),o=(0,i.useRef)({width:0,height:0,top:0,left:0,right:0}),{nonce:c}=(0,i.useContext)(h.Q);return(0,i.useInsertionEffect)(()=>{const{width:e,height:t,top:i,left:l,right:d}=o.current;if(s||!r.current||!e||!t)return;const x="left"===a?"left: ".concat(l):"right: ".concat(d);r.current.dataset.motionPopId=n;const h=document.createElement("style");return c&&(h.nonce=c),document.head.appendChild(h),h.sheet&&h.sheet.insertRule('\n          [data-motion-pop-id="'.concat(n,'"] {\n            position: absolute !important;\n            width: ').concat(e,"px !important;\n            height: ").concat(t,"px !important;\n            ").concat(x,"px !important;\n            top: ").concat(i,"px !important;\n          }\n        ")),()=>{document.head.contains(h)&&document.head.removeChild(h)}},[s]),(0,l.jsx)(m,{isPresent:s,childRef:r,sizeRef:o,children:i.cloneElement(t,{ref:r})})}const u=e=>{let{children:t,initial:s,isPresent:a,onExitComplete:n,custom:o,presenceAffectsLayout:x,mode:h,anchorX:m}=e;const u=(0,r.M)(g),f=(0,i.useId)();let b=!0,j=(0,i.useMemo)(()=>(b=!1,{id:f,initial:s,isPresent:a,custom:o,onExitComplete:e=>{u.set(e,!0);for(const t of u.values())if(!t)return;n&&n()},register:e=>(u.set(e,!1),()=>u.delete(e))}),[a,u,n]);return x&&b&&(j=(0,c.A)({},j)),(0,i.useMemo)(()=>{u.forEach((e,t)=>u.set(t,!1))},[a]),i.useEffect(()=>{!a&&!u.size&&n&&n()},[a]),"popLayout"===h&&(t=(0,l.jsx)(p,{isPresent:a,anchorX:m,children:t})),(0,l.jsx)(d.t.Provider,{value:j,children:t})};function g(){return new Map}var f=s(917);const b=e=>e.key||"";function j(e){const t=[];return i.Children.forEach(e,e=>{(0,i.isValidElement)(e)&&t.push(e)}),t}const y=e=>{let{children:t,custom:s,initial:a=!0,onExitComplete:c,presenceAffectsLayout:d=!0,mode:x="sync",propagate:h=!1,anchorX:m="left"}=e;const[p,g]=(0,f.xQ)(h),y=(0,i.useMemo)(()=>j(t),[t]),v=h&&!p?[]:y.map(b),w=(0,i.useRef)(!0),N=(0,i.useRef)(y),k=(0,r.M)(()=>new Map),[P,I]=(0,i.useState)(y),[C,E]=(0,i.useState)(y);(0,o.E)(()=>{w.current=!1,N.current=y;for(let e=0;e<C.length;e++){const t=b(C[e]);v.includes(t)?k.delete(t):!0!==k.get(t)&&k.set(t,!1)}},[C,v.length,v.join("-")]);const A=[];if(y!==P){let e=[...y];for(let t=0;t<C.length;t++){const s=C[t],i=b(s);v.includes(i)||(e.splice(t,0,s),A.push(s))}return"wait"===x&&A.length&&(e=A),E(j(e)),I(y),null}const{forceRender:T}=(0,i.useContext)(n.L);return(0,l.jsx)(l.Fragment,{children:C.map(e=>{const t=b(e),i=!(h&&!p)&&(y===C||v.includes(t));return(0,l.jsx)(u,{isPresent:i,initial:!(w.current&&!a)&&void 0,custom:s,presenceAffectsLayout:d,mode:x,onExitComplete:i?void 0:()=>{if(!k.has(t))return;k.set(t,!0);let e=!0;k.forEach(t=>{t||(e=!1)}),e&&(null===T||void 0===T||T(),E(N.current),h&&(null===g||void 0===g||g()),c&&c())},anchorX:m,children:e},t)})})},v=()=>(0,l.jsxs)("svg",{xmlns:"http://www.w3.org/2000/svg",width:"24",height:"24",viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:"2",strokeLinecap:"round",strokeLinejoin:"round",children:[(0,l.jsx)("path",{d:"M17 21v-2a4 4 0 0 0-4-4H5a4 4 0 0 0-4 4v2"}),(0,l.jsx)("circle",{cx:"9",cy:"7",r:"4"}),(0,l.jsx)("path",{d:"M23 21v-2a4 4 0 0 0-3-3.87"}),(0,l.jsx)("path",{d:"M16 3.13a4 4 0 0 1 0 7.75"})]}),w=()=>(0,l.jsxs)("svg",{xmlns:"http://www.w3.org/2000/svg",width:"24",height:"24",viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:"2",strokeLinecap:"round",strokeLinejoin:"round",children:[(0,l.jsx)("path",{d:"M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"}),(0,l.jsx)("polyline",{points:"14 2 14 8 20 8"}),(0,l.jsx)("line",{x1:"16",y1:"13",x2:"8",y2:"13"}),(0,l.jsx)("line",{x1:"16",y1:"17",x2:"8",y2:"17"}),(0,l.jsx)("polyline",{points:"10 9 9 9 8 9"})]}),N=()=>(0,l.jsxs)("svg",{xmlns:"http://www.w3.org/2000/svg",width:"24",height:"24",viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:"2",strokeLinecap:"round",strokeLinejoin:"round",children:[(0,l.jsx)("rect",{x:"3",y:"3",width:"18",height:"18",rx:"2",ry:"2"}),(0,l.jsx)("line",{x1:"3",y1:"9",x2:"21",y2:"9"}),(0,l.jsx)("line",{x1:"9",y1:"21",x2:"9",y2:"9"})]}),k=()=>(0,l.jsxs)("svg",{xmlns:"http://www.w3.org/2000/svg",width:"24",height:"24",viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:"2",strokeLinecap:"round",strokeLinejoin:"round",children:[(0,l.jsx)("polyline",{points:"16 18 22 12 16 6"}),(0,l.jsx)("polyline",{points:"8 6 2 12 8 18"})]}),P=()=>(0,l.jsx)("svg",{xmlns:"http://www.w3.org/2000/svg",width:"24",height:"24",viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:"2",strokeLinecap:"round",strokeLinejoin:"round",children:(0,l.jsx)("polyline",{points:"6 9 12 15 18 9"})}),I="/personalwebsite";function C(){const[e,t]=(0,i.useState)("overview"),[s,n]=(0,i.useState)(null),[r,o]=(0,i.useState)(0),c=()=>n(null),d=[{id:"overview",label:"Overview"},{id:"process",label:"Process"},{id:"prototyping",label:"Prototypes"},{id:"outcome",label:"Outcome"}],x=[{name:"Low-Fi Wireframes",image:"".concat(I,"/assets/lowFi_hci.jpg"),description:"Initial sketches to map out the core user flow for both participant and proctor interfaces, focusing on task sequence and control points."},{name:"Mid-Fi Digital Prototype",image:"".concat(I,"/assets/midFi_hci.png"),description:"Digital wireframes built in Figma to test interaction patterns, button placement, and the 'Wizard of Oz' control panel for the proctor."},{name:"High-Fi Apparatus",image:"".concat(I,"/assets/highFi_hci.png"),description:"The final Unity application with full visual design and MQTT backend integration, used for the remote user testing sessions."}];(0,i.useEffect)(()=>{const e=()=>{const e=d.map(e=>document.getElementById(e.id)),s=window.scrollY+window.innerHeight/2;for(const i of e)if(i&&i.offsetTop<=s&&i.offsetTop+i.offsetHeight>s){t(i.id);break}};return window.addEventListener("scroll",e),()=>window.removeEventListener("scroll",e)},[]);const h=e=>{var s;t(e),null===(s=document.getElementById(e))||void 0===s||s.scrollIntoView({behavior:"smooth"})};return(0,l.jsxs)("div",{className:"bg-gray-50 font-sans text-gray-800",children:[(0,l.jsxs)("div",{className:"relative h-screen flex items-center justify-center bg-gradient-to-br from-gray-900 to-slate-800 text-white overflow-hidden",children:[(0,l.jsx)("div",{className:"absolute inset-0 bg-[url('https://www.transparenttextures.com/patterns/cubes.png')] opacity-5"}),(0,l.jsx)("div",{className:"absolute inset-0 flex items-center justify-center",children:[...Array(4)].map((e,t)=>(0,l.jsx)(a.P.div,{className:"absolute border border-sky-500/20 rounded-full",style:{width:"".concat(25*(t+1),"vw"),height:"".concat(25*(t+1),"vw")},animate:{scale:[1,1.05,1],opacity:[.1,.3,.1]},transition:{duration:8+2*t,repeat:1/0,ease:"easeInOut"}},t))}),(0,l.jsxs)(a.P.div,{initial:{opacity:0,y:20},animate:{opacity:1,y:0},transition:{duration:.8},className:"text-center px-4 z-10",children:[(0,l.jsx)("h1",{className:"text-5xl md:text-7xl font-bold tracking-tighter leading-tight",children:"When Machines Train Humans"}),(0,l.jsx)("p",{className:"text-xl md:text-2xl text-sky-300/80 mt-6 max-w-3xl mx-auto",children:"A UX Research Study on AI Voice Agents in Instructional Contexts"}),(0,l.jsx)("p",{className:"text-lg text-sky-200/70 mt-4",children:"Team: Dustin Chan, Ian Galendez, Abhayjit Sodhi, Elif Onem, Ryan Luk"}),(0,l.jsx)(a.P.a,{href:"#project-content",onClick:e=>{e.preventDefault(),h("overview")},className:"mt-12 inline-block px-8 py-4 bg-sky-500 text-white font-bold rounded-xl shadow-lg hover:bg-sky-400 transition-transform hover:scale-105",children:"Explore The Research"})]}),(0,l.jsx)(a.P.div,{className:"absolute bottom-10",animate:{y:[0,10,0]},transition:{duration:2,repeat:1/0},children:(0,l.jsx)(P,{className:"w-8 h-8 text-white/50"})})]}),(0,l.jsx)("section",{id:"stats",className:"bg-white py-16 shadow-lg",children:(0,l.jsxs)("div",{className:"max-w-7xl mx-auto px-4",children:[(0,l.jsx)("h2",{className:"text-3xl font-bold text-center mb-12 text-slate-800",children:"Key Research Takeaways"}),(0,l.jsx)("div",{className:"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-8",children:[{value:"0",label:"Statistically Significant Differences",icon:"\ud83d\udcca",description:"Performance metrics showed no significant variation between voice types."},{value:"Clarity",label:"Preferred over 'Human-ness'",icon:"\ud83d\udc4d",description:"Users rated the clear, consistent GPT agent highest for understandability."},{value:"Neutrality",label:"Viewed as a Positive",icon:"\ud83e\udd16",description:"Task-centric AI voices allowed users to focus without social distractions."},{value:"Instruction",label:"Key Application Area",icon:"\ud83c\udf93",description:"Findings are crucial for educational and training-based AI systems."}].map((e,t)=>(0,l.jsxs)(a.P.div,{className:"bg-slate-50 p-6 rounded-xl border border-slate-200 text-center",initial:{opacity:0,y:20},whileInView:{opacity:1,y:0},transition:{duration:.5,delay:.1*t},viewport:{once:!0},children:[(0,l.jsx)("div",{className:"text-4xl mb-3 inline-block bg-sky-100 p-3 rounded-full",children:e.icon}),(0,l.jsx)("h3",{className:"text-2xl font-bold text-sky-600",children:e.value}),(0,l.jsx)("p",{className:"text-slate-700 font-semibold mt-2",children:e.label}),(0,l.jsx)("p",{className:"text-slate-500 text-sm mt-2",children:e.description})]},t))})]})}),(0,l.jsx)("div",{className:"sticky top-0 z-30 bg-white/90 backdrop-blur-lg shadow-md",children:(0,l.jsx)("div",{className:"max-w-7xl mx-auto px-4",children:(0,l.jsx)("div",{className:"flex justify-center border-b border-gray-200",children:d.map(t=>(0,l.jsx)("button",{onClick:()=>h(t.id),className:"px-4 md:px-6 py-4 font-semibold whitespace-nowrap border-b-2 transition-colors duration-300 ".concat(e===t.id?"border-sky-500 text-sky-600":"border-transparent text-gray-500 hover:text-sky-600 hover:border-sky-300"),children:t.label},t.id))})})}),(0,l.jsxs)("main",{id:"project-content",className:"max-w-5xl mx-auto px-4 py-16 space-y-24",children:[(0,l.jsx)("section",{id:"overview",className:"scroll-mt-24 py-28",children:(0,l.jsxs)("div",{className:"max-w-4xl mx-auto text-center",children:[(0,l.jsx)("h2",{className:"text-5xl font-extrabold text-slate-900 mb-8",children:"Overview"}),(0,l.jsx)("p",{className:"text-gray-700 text-lg leading-relaxed mb-6",children:"AI voice agents are becoming increasingly lifelike, but does sounding more human actually help users perform better during complex tasks? Our research set out to answer this question by isolating the impact of voice tone\u2014robotic, neutral, or human-like\u2014on users' ability to complete step-by-step instructions."}),(0,l.jsxs)("div",{className:"bg-slate-100 p-6 rounded-xl my-8 text-left",children:[(0,l.jsx)("h3",{className:"text-xl font-bold text-slate-800 mb-3",children:"Goal"}),(0,l.jsx)("p",{className:"text-gray-700",children:"We aimed to test whether clarity or human-likeness in AI voice agents better supports task success. Our system gave us full control over voice playback, task flow, and interface\u2014enabling us to rigorously evaluate voice type performance and user preference."})]}),(0,l.jsxs)("div",{className:"bg-slate-100 p-6 rounded-xl my-8 text-left",children:[(0,l.jsx)("h3",{className:"text-xl font-bold text-slate-800 mb-3",children:"Problem"}),(0,l.jsx)("p",{className:"text-gray-700",children:"While AI voices are often designed for personality, little is known about their effectiveness for instructional tasks. Can a synthetic voice compete with a real human in helping people complete complex multi-step tasks?"})]}),(0,l.jsxs)("div",{className:"bg-slate-100 p-6 rounded-xl my-8 text-left",children:[(0,l.jsx)("h3",{className:"text-xl font-bold text-slate-800 mb-3",children:"How Research Shifted Our Direction"}),(0,l.jsx)("p",{className:"text-gray-700",children:"Early attempts to use origami instruction via audio failed\u2014the task was too complex to isolate voice impact. This led us to design a simplified but controlled digital task environment, enabling us to evaluate voices without interference from task complexity."})]}),(0,l.jsxs)("div",{className:"grid md:grid-cols-2 gap-6 mt-12",children:[(0,l.jsxs)("div",{className:"bg-white p-6 rounded-xl shadow-sm border",children:[(0,l.jsxs)("h3",{className:"text-xl font-bold text-slate-800 mb-3 flex items-center",children:[(0,l.jsx)(v,{className:"mr-2"})," Role"]}),(0,l.jsx)("p",{className:"text-gray-600",children:"UX Researcher / System Designer / Study Facilitator"})]}),(0,l.jsxs)("div",{className:"bg-white p-6 rounded-xl shadow-sm border",children:[(0,l.jsxs)("h3",{className:"text-xl font-bold text-slate-800 mb-3 flex items-center",children:[(0,l.jsx)(w,{className:"mr-2"})," Duration"]}),(0,l.jsx)("p",{className:"text-gray-600",children:"8 Weeks"})]}),(0,l.jsxs)("div",{className:"bg-white p-6 rounded-xl shadow-sm border",children:[(0,l.jsxs)("h3",{className:"text-xl font-bold text-slate-800 mb-3 flex items-center",children:[(0,l.jsx)(N,{className:"mr-2"})," Tools"]}),(0,l.jsx)("p",{className:"text-gray-600",children:"Figma, Unity, Excel, GoStats.jar, MQTT, Framer Motion"})]}),(0,l.jsxs)("div",{className:"bg-white p-6 rounded-xl shadow-sm border",children:[(0,l.jsxs)("h3",{className:"text-xl font-bold text-slate-800 mb-3 flex items-center",children:[(0,l.jsx)(k,{className:"mr-2"})," Skills"]}),(0,l.jsx)("p",{className:"text-gray-600",children:"Wizard of Oz testing, ANOVA analysis, qualitative interviews, interface prototyping, mixed-method evaluation"})]})]})]})}),(0,l.jsx)("section",{id:"process",className:"scroll-mt-24 py-28",children:(0,l.jsxs)("div",{className:"max-w-4xl mx-auto",children:[(0,l.jsx)("h2",{className:"text-5xl font-extrabold text-slate-900 mb-12 text-center",children:"Our Research Process"}),(0,l.jsxs)("div",{className:"mb-20",children:[(0,l.jsx)("h3",{className:"text-3xl font-bold text-slate-800 mb-6 text-center",children:"Phase 1 \u2013 Ideation"}),(0,l.jsx)("h4",{className:"text-xl font-semibold text-slate-700 mb-3",children:"Who Are We Designing For?"}),(0,l.jsx)("p",{className:"text-gray-700 mb-4",children:"Task-focused users learning via voice instructions. The context: digital instructions for physical tasks like origami or shape-matching."}),(0,l.jsx)("h4",{className:"text-xl font-semibold text-slate-700 mb-3",children:"Early Explorations"}),(0,l.jsx)("p",{className:"text-gray-700 mb-4",children:"Our first prototype asked users to fold origami via audio. But we quickly found that the task complexity overwhelmed the ability to test voice clarity. This pivoted our direction."}),(0,l.jsx)("img",{src:"".concat(I,"/assets/origami_prototype.png"),alt:"Origami Prototype",className:"w-full rounded-xl shadow-lg mb-6"})]}),(0,l.jsxs)("div",{className:"mb-20",children:[(0,l.jsx)("h3",{className:"text-3xl font-bold text-slate-800 mb-6 text-center",children:"Phase 2 \u2013 System Design"}),(0,l.jsx)("p",{className:"text-gray-700 mb-4",children:"We designed a fully controlled Unity system with two interfaces:"}),(0,l.jsxs)("ul",{className:"list-disc list-inside pl-4 text-gray-700 mb-6 space-y-2",children:[(0,l.jsxs)("li",{children:[(0,l.jsx)("strong",{children:"User Interface:"})," A 5x5 grid with draggable shapes in various colors."]}),(0,l.jsxs)("li",{children:[(0,l.jsx)("strong",{children:"Proctor Interface:"})," A manual voice playback panel that allowed researchers to simulate AI voice control in real-time."]})]}),(0,l.jsx)("p",{className:"text-gray-700 mb-6",children:'This "Wizard of Oz" method let us control every aspect of the interaction while simulating different AI agents.'}),(0,l.jsxs)("div",{className:"flex flex-col md:flex-row justify-center gap-8 w-full my-8",children:[(0,l.jsxs)("div",{className:"flex-1 flex flex-col items-center",children:[(0,l.jsx)("img",{src:"".concat(I,"/assets/highFi_hci.png"),alt:"User's Interface",className:"w-full h-auto max-h-[80vh] object-contain rounded-xl shadow-xl"}),(0,l.jsx)("p",{className:"text-center text-lg font-medium text-slate-700 mt-4",children:"User's Interface"})]}),(0,l.jsxs)("div",{className:"flex-1 flex flex-col items-center",children:[(0,l.jsx)("img",{src:"".concat(I,"/assets/proctorUi_hci.png"),alt:"Proctor's Interface",className:"w-full h-auto max-h-[80vh] object-contain rounded-xl shadow-xl"}),(0,l.jsx)("p",{className:"text-center text-lg font-medium text-slate-700 mt-4",children:"Proctor's Interface"})]})]}),(0,l.jsxs)("div",{className:"bg-blue-50 p-6 rounded-xl border border-blue-200 mt-8",children:[(0,l.jsx)("h4",{className:"text-xl font-semibold text-blue-800 mb-3",children:"Research Questions"}),(0,l.jsxs)("ul",{className:"list-disc list-inside pl-4 text-blue-900 space-y-2",children:[(0,l.jsx)("li",{children:"How do different AI voice tones affect task success in instructional contexts?"}),(0,l.jsx)("li",{children:"Do users prefer human-like voices, or do they value clarity and consistency more?"}),(0,l.jsx)("li",{children:"Can synthetic voices rival human guidance in complex digital environments?"})]})]})]}),(0,l.jsxs)("div",{className:"mb-20",children:[(0,l.jsx)("h3",{className:"text-3xl font-bold text-slate-800 mb-6 text-center",children:"Phase 3 \u2013 Prototyping"}),(0,l.jsx)("p",{className:"text-gray-700 mb-4",children:"We iterated through several fidelity levels:"}),(0,l.jsxs)("ul",{className:"list-disc list-inside pl-4 text-gray-700 mb-6 space-y-2",children:[(0,l.jsxs)("li",{children:[(0,l.jsx)("strong",{children:"Low-Fidelity Wireframes:"})," Sketches to define core layout and flow"]}),(0,l.jsxs)("li",{children:[(0,l.jsx)("strong",{children:"Mid-Fidelity Prototype:"})," Figma prototype to test control panel logic"]}),(0,l.jsxs)("li",{children:[(0,l.jsx)("strong",{children:"High-Fidelity Interface:"})," Unity implementation of the grid, shapes, and instruction playback"]})]}),(0,l.jsx)("p",{className:"text-gray-700",children:"Each prototype focused on clarity of task flow, audio pacing, and researcher control."})]}),(0,l.jsxs)("div",{className:"mb-20",children:[(0,l.jsx)("h3",{className:"text-3xl font-bold text-slate-800 mb-6 text-center",children:"Phase 4 \u2013 Evaluation"}),(0,l.jsxs)("div",{className:"grid md:grid-cols-2 gap-8",children:[(0,l.jsxs)("div",{children:[(0,l.jsx)("h4",{className:"text-xl font-semibold text-slate-700 mb-3",children:"Participants"}),(0,l.jsx)("p",{className:"text-gray-700 mb-4",children:"15 students (ages 18\u201329)"}),(0,l.jsx)("h4",{className:"text-xl font-semibold text-slate-700 mb-3",children:"Design"}),(0,l.jsx)("p",{className:"text-gray-700 mb-2",children:"Between-subjects experiment with 3 voice conditions:"}),(0,l.jsxs)("ul",{className:"list-disc list-inside pl-4 text-gray-700 space-y-1",children:[(0,l.jsx)("li",{children:"Human"}),(0,l.jsx)("li",{children:"Robotic"}),(0,l.jsx)("li",{children:"ChatGPT Neutral (Ember)"})]})]}),(0,l.jsxs)("div",{children:[(0,l.jsx)("h4",{className:"text-xl font-semibold text-slate-700 mb-3",children:"Data Collected"}),(0,l.jsxs)("ul",{className:"list-disc list-inside pl-4 text-gray-700 space-y-2",children:[(0,l.jsx)("li",{children:"Quantitative data: completion times, error rates, number of replays"}),(0,l.jsx)("li",{children:"Qualitative data: interviews, open-ended feedback"})]})]})]})]})]})}),(0,l.jsxs)("section",{id:"prototyping",className:"scroll-mt-24",children:[(0,l.jsx)("h2",{className:"text-5xl font-extrabold text-slate-900 mb-12 text-center",children:"Design Evolution & Testing"}),(0,l.jsxs)("div",{className:"grid lg:grid-cols-2 gap-8 lg:gap-12 items-center",children:[(0,l.jsx)("div",{className:"space-y-6",children:x.map((e,t)=>(0,l.jsx)(a.P.div,{whileHover:{y:-5},className:"cursor-pointer",onClick:()=>(e=>o(e))(t),children:(0,l.jsxs)("div",{className:"bg-white p-6 rounded-xl border shadow-sm transition-shadow hover:shadow-lg",children:[(0,l.jsx)("h4",{className:"font-bold text-lg text-slate-800",children:e.name}),(0,l.jsx)("p",{className:"text-gray-600 text-sm",children:e.description})]})},e.name))}),(0,l.jsxs)("div",{className:"relative h-96 lg:h-auto min-h-[450px]",children:[(0,l.jsx)(y,{mode:"wait",children:(0,l.jsx)(a.P.div,{className:"absolute inset-0 bg-cover bg-center rounded-xl shadow-2xl border-4 border-white cursor-pointer",style:{backgroundImage:"url(".concat(x[r].image,"), url('https://placehold.co/600x450/e2e8f0/94a3b8?text=Image+Not+Found')")},onClick:()=>{return e=x[r].image,n(e);var e},initial:{opacity:0,scale:.95},animate:{opacity:1,scale:1},transition:{duration:.5}},x[r].image)}),(0,l.jsx)("p",{className:"absolute bottom-2 left-1/2 -translate-x-1/2 text-center text-sm text-gray-500 bg-white bg-opacity-75 px-3 py-1 rounded",children:"Click an image to enlarge."})]})]})]}),(0,l.jsx)("section",{id:"outcome",className:"scroll-mt-24",children:(0,l.jsxs)("div",{className:"max-w-4xl mx-auto",children:[(0,l.jsx)("h2",{className:"text-5xl font-extrabold text-slate-900 mb-12 text-center",children:"Outcome & Final Conclusion"}),(0,l.jsxs)("div",{className:"bg-white p-8 rounded-2xl shadow-xl border mb-12",children:[(0,l.jsx)("h3",{className:"text-3xl font-bold text-slate-800 mb-6 text-center",children:"Key Findings"}),(0,l.jsxs)("div",{className:"grid md:grid-cols-2 gap-8 mb-8",children:[(0,l.jsxs)("div",{children:[(0,l.jsx)("h4",{className:"text-xl font-semibold text-slate-700 mb-3",children:"Quantitative Results"}),(0,l.jsx)("p",{className:"text-gray-700 mb-4",children:"No statistical difference in performance (ANOVA)"}),(0,l.jsx)("p",{className:"text-gray-700 mb-4",children:"Participants preferred the clearest, most neutral voice"})]}),(0,l.jsxs)("div",{children:[(0,l.jsx)("h4",{className:"text-xl font-semibold text-slate-700 mb-3",children:"Qualitative Insights"}),(0,l.jsx)("p",{className:"text-gray-700 mb-4",children:"Human voices were often rated as less understandable"}),(0,l.jsx)("p",{className:"text-gray-700",children:"Robotic voices were less engaging but more predictable"})]})]}),(0,l.jsxs)("div",{className:"bg-green-50 p-6 rounded-xl border border-green-200",children:[(0,l.jsx)("h4",{className:"text-xl font-semibold text-green-800 mb-3",children:"Answer"}),(0,l.jsx)("p",{className:"text-gray-700",children:"Our study found no statistically significant performance differences between voice types\u2014but participants overwhelmingly preferred the clearest voice (ChatGPT's neutral tone). Human-like voices often introduced inconsistencies, while robotic voices felt impersonal."})]})]}),(0,l.jsxs)("div",{className:"bg-sky-600 text-white p-8 rounded-2xl shadow-xl mb-12",children:[(0,l.jsx)("h3",{className:"text-3xl font-bold mb-6 text-center",children:"Impact"}),(0,l.jsx)("p",{className:"text-lg mb-4",children:"Our findings suggest AI voices used for instruction should prioritize clarity and pacing over personality. This has major implications for voice interfaces in education, training, and task-based digital experiences."})]}),(0,l.jsxs)("div",{className:"bg-white p-8 rounded-2xl shadow-xl border",children:[(0,l.jsx)("h3",{className:"text-3xl font-bold text-slate-800 mb-6 text-center",children:"Reflections & Takeaways"}),(0,l.jsxs)("div",{className:"grid md:grid-cols-2 gap-8 mb-8",children:[(0,l.jsxs)("div",{children:[(0,l.jsx)("h4",{className:"text-xl font-semibold text-slate-700 mb-3",children:"Build What You Can Control"}),(0,l.jsx)("p",{className:"text-gray-700",children:"Our own system let us manipulate every variable. This was critical for isolating the voice impact."})]}),(0,l.jsxs)("div",{children:[(0,l.jsx)("h4",{className:"text-xl font-semibold text-slate-700 mb-3",children:"Real Voices \u2260 Better Experience"}),(0,l.jsx)("p",{className:"text-gray-700",children:"Human tone doesn't always translate into clarity. Simplicity and pacing often matter more."})]}),(0,l.jsxs)("div",{children:[(0,l.jsx)("h4",{className:"text-xl font-semibold text-slate-700 mb-3",children:"Adapt to Your Audience"}),(0,l.jsx)("p",{className:"text-gray-700",children:"We designed the UI for remote testing, accessibility, and ease of voice mapping."})]})]}),(0,l.jsxs)("div",{className:"bg-purple-50 p-6 rounded-xl border border-purple-200",children:[(0,l.jsx)("h4",{className:"text-xl font-semibold text-purple-800 mb-3",children:"Future Work"}),(0,l.jsxs)("ul",{className:"list-disc list-inside pl-4 text-purple-900 space-y-2",children:[(0,l.jsx)("li",{children:"Automating data collection to reduce proctor burden"}),(0,l.jsx)("li",{children:"Testing adaptive voices that change based on user behavior"}),(0,l.jsx)("li",{children:"Expanding the study to include different age groups and multilingual voice agents"}),(0,l.jsx)("li",{children:"Incorporating multitasking or distraction factors to better simulate real-world use"})]})]})]})]})})]}),(0,l.jsx)(y,{children:s&&(0,l.jsxs)(a.P.div,{className:"fixed inset-0 bg-black/80 flex items-center justify-center z-50 p-4",initial:{opacity:0},animate:{opacity:1},exit:{opacity:0},onClick:c,children:[(0,l.jsx)(a.P.img,{src:s,alt:"Enlarged view",className:"max-w-full max-h-full object-contain rounded-lg shadow-2xl",initial:{scale:.8},animate:{scale:1},exit:{scale:.8},onClick:e=>e.stopPropagation(),onError:e=>{e.currentTarget.src="https://placehold.co/1200x900/1e293b/94a3b8?text=Image+Load+Error"}}),(0,l.jsx)("button",{onClick:c,className:"absolute top-4 right-4 text-white/80 text-5xl hover:text-white",children:"\xd7"})]})})]})}}}]);
//# sourceMappingURL=459.f60b5b39.chunk.js.map